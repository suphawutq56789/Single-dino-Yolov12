# YOLOv12 Triple Input - GREYSCALE VERSION

## ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Greyscale Triple Input

### ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°

‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô greyscale ‡∏ô‡∏µ‡πâ‡πÅ‡∏õ‡∏•‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡∏à‡∏≤‡∏Å RGB (9 channels = 3 images √ó 3 RGB channels) ‡πÄ‡∏õ‡πá‡∏ô **GREYSCALE (3 channels = 3 images √ó 1 greyscale channel)**

### ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ç‡∏≠‡∏á Greyscale:
- ‚úÖ **‡πÉ‡∏ä‡πâ memory ‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤** (~33% ‡∏Ç‡∏≠‡∏á RGB)
- ‚úÖ **‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô**
- ‚úÖ **‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏™‡∏µ** (‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á, satellite imagery)

---

## üöÄ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á

### 1. ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏ü‡∏•‡πå `ultralytics/data/build.py`

‡∏´‡∏≤‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà 103 ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å:
```python
from ultralytics.data.triple_dataset import TripleInputDataset
```

‡πÄ‡∏õ‡πá‡∏ô:
```python
from ultralytics.data.triple_dataset_greyscale import TripleInputDatasetGreyscale as TripleInputDataset
```

**‡∏´‡∏£‡∏∑‡∏≠** ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏ö‡∏•‡πá‡∏≠‡∏Å (‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î 101-123):

```python
if is_triple_input:
    # Import and use TripleInputDatasetGreyscale for greyscale triple input
    from ultralytics.data.triple_dataset_greyscale import TripleInputDatasetGreyscale
    from ultralytics.utils import LOGGER
    LOGGER.info(f"Triple input GREYSCALE structure detected - using TripleInputDatasetGreyscale for {mode}")

    return TripleInputDatasetGreyscale(
        img_path=img_path,
        imgsz=cfg.imgsz,
        batch_size=batch,
        augment=mode == "train",  # augmentation
        hyp=cfg,  # hyperparameters
        rect=cfg.rect or rect,  # rectangular batches
        cache=cfg.cache or None,
        single_cls=cfg.single_cls or False,
        stride=int(stride),
        pad=0.0 if mode == "train" else 0.5,
        prefix=colorstr(f"{mode}: "),
        classes=cfg.classes,
        fraction=cfg.fraction if mode == "train" else 1.0,
        data=data,
        task=getattr(cfg, 'task', 'detect'),
    )
```

---

## üìù ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á Training

```bash
# Basic training with greyscale
python "train_grey scale.py" --data dataset.yaml --epochs 100 --batch 8

# Training with DINOv3 P0 preprocessing (greyscale)
python "train_grey scale.py" --data dataset.yaml --integrate initial --dinov3-size small

# Training without DINOv3 (standard greyscale triple input)
python "train_grey scale.py" --data dataset.yaml --integrate nodino --variant s

# Training with P3 feature enhancement
python "train_grey scale.py" --data dataset.yaml --integrate p3 --dinov3-size base

# Training with dual DINOv3 integration (P0 + P3)
python "train_grey scale.py" --data dataset.yaml --integrate p0p3 --dinov3-size base
```

### ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç

| Parameter | Description | Default |
|-----------|-------------|---------|
| `--data` | ‡πÑ‡∏ü‡∏•‡πå config ‡∏Ç‡∏≠‡∏á dataset (*.yaml) | **required** |
| `--integrate` | DINOv3 integration: `initial`, `nodino`, `p3`, `p0p3` | `initial` |
| `--dinov3-size` | ‡∏Ç‡∏ô‡∏≤‡∏î DINOv3: `small`, `base`, `large`, `giant` | `small` |
| `--variant` | YOLOv12 variant: `n`, `s`, `m`, `l`, `x` | `s` |
| `--epochs` | ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô epochs | `100` |
| `--batch` | Batch size | `8` |
| `--imgsz` | ‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û | `224` |
| `--device` | Device: `0`, `1`, `cpu` | `0` |

---

## üìÇ ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Dataset

Dataset ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ:

```
dataset/
‚îú‚îÄ‚îÄ primary/
‚îÇ   ‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ image1.jpg
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ image2.jpg
‚îÇ   ‚îî‚îÄ‚îÄ val/
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ detail1/
‚îÇ   ‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ image1.jpg
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ image2.jpg
‚îÇ   ‚îî‚îÄ‚îÄ val/
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ detail2/
‚îÇ   ‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ image1.jpg
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ image2.jpg
‚îÇ   ‚îî‚îÄ‚îÄ val/
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ labels/
    ‚îú‚îÄ‚îÄ train/
    ‚îÇ   ‚îú‚îÄ‚îÄ image1.txt
    ‚îÇ   ‚îî‚îÄ‚îÄ image2.txt
    ‚îî‚îÄ‚îÄ val/
        ‚îî‚îÄ‚îÄ ...
```

**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** ‡πÅ‡∏°‡πâ‡∏ß‡πà‡∏≤‡∏†‡∏≤‡∏û‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô RGB (.jpg), ‡πÇ‡∏Ñ‡πâ‡∏î greyscale ‡∏à‡∏∞‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏õ‡πá‡∏ô greyscale ‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥

---

## ‚öôÔ∏è ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á

### ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà:
1. **`train_grey scale.py`** - ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå training ‡πÅ‡∏ö‡∏ö greyscale
2. **`ultralytics/data/triple_dataset_greyscale.py`** - Dataset class ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö greyscale
3. **`GREYSCALE_USAGE.md`** - ‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ

### ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:
1. **`ultralytics/data/build.py`** (‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î 103) - ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô import ‡πÄ‡∏õ‡πá‡∏ô greyscale version

---

## üîß ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö

### ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ greyscale ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ:

```python
# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô greyscale
from ultralytics.data.triple_dataset_greyscale import TripleInputDatasetGreyscale
import cv2

# ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß
img = cv2.imread('test.jpg', cv2.IMREAD_GRAYSCALE)
print(f"Image shape: {img.shape}")  # ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏õ‡πá‡∏ô (H, W) ‡πÑ‡∏°‡πà‡∏°‡∏µ channel
print(f"Image dtype: {img.dtype}")  # ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏õ‡πá‡∏ô uint8
```

---

## üÜö ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö RGB vs Greyscale

| Feature | RGB Version | Greyscale Version |
|---------|-------------|-------------------|
| Channels | 9 (3 images √ó 3 RGB) | 3 (3 images √ó 1 greyscale) |
| Memory | ~3x more | Baseline |
| Speed | Slower | Faster |
| Color info | ‚úÖ Yes | ‚ùå No |
| File | `train_triple_dinov3.py` | `train_grey scale.py` |
| Dataset | `triple_dataset.py` | `triple_dataset_greyscale.py` |

---

## ‚ùó ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á

1. **HSV Augmentations ‡∏ñ‡∏π‡∏Å‡∏õ‡∏¥‡∏î‡πÅ‡∏•‡πâ‡∏ß** - ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ greyscale ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏µ
2. **Visualization ‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤** - plots ‡∏ñ‡∏π‡∏Å‡∏õ‡∏¥‡∏î‡πÑ‡∏ß‡πâ
3. **Color-based features ‡πÑ‡∏°‡πà‡∏°‡∏µ** - ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏µ
4. **‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç build.py** - ‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏°‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç import ‡πÉ‡∏ô build.py

---

## üêõ ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: RuntimeError: expected input to have 9 channels, but got 3

**‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏:** ‡∏¢‡∏±‡∏á‡πÉ‡∏ä‡πâ RGB version ‡∏≠‡∏¢‡∏π‡πà

**‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:** ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç `ultralytics/data/build.py` ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß

---

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡∏†‡∏≤‡∏û‡∏¢‡∏±‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏µ

**‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏:** Dataset ‡∏¢‡∏±‡∏á‡πÉ‡∏ä‡πâ RGB loader

**‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:** ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ build.py import `triple_dataset_greyscale` ‡πÅ‡∏•‡πâ‡∏ß

---

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: Channel mismatch in validation

**‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏:** ‡∏õ‡∏Å‡∏ï‡∏¥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö P0 integration

**‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:** ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£ training ‡∏à‡∏∞‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡πÅ‡∏ï‡πà final validation ‡∏≠‡∏≤‡∏à error

---

## üìö ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°

```bash
# Training with small model, no DINOv3
python "train_grey scale.py" --data ../DATASET\ NEW/data.yaml --integrate nodino --variant n --epochs 50

# Training with base DINOv3, P0 only
python "train_grey scale.py" --data ../DATASET\ NEW/data.yaml --integrate initial --dinov3-size base --variant s --epochs 100

# Training with large DINOv3, dual integration
python "train_grey scale.py" --data ../DATASET\ NEW/data.yaml --integrate p0p3 --dinov3-size large --variant m --epochs 200 --batch 4

# CPU training (for testing)
python "train_grey scale.py" --data ../DATASET\ NEW/data.yaml --integrate nodino --device cpu --epochs 10 --batch 2
```

---

## üìä ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á

- **Memory usage:** ~33% ‡∏Ç‡∏≠‡∏á RGB version
- **Training speed:** ~20-30% ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
- **Accuracy:** ‡∏≠‡∏≤‡∏à‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ RGB ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡∏ñ‡πâ‡∏≤ color information ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
- **Best for:** Structural detection, texture analysis, satellite imagery

---

## üìû ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠ / Support

‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏™‡∏á‡∏™‡∏±‡∏¢:
1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç `build.py` ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö dataset structure
3. ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ `--integrate nodino` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö debugging
4. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö error message ‡πÅ‡∏•‡∏∞ traceback

---

## ‚úÖ Checklist ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏° Training

- [ ] ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç `ultralytics/data/build.py` ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô import ‡πÄ‡∏õ‡πá‡∏ô greyscale
- [ ] ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö dataset structure (primary, detail1, detail2)
- [ ] ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ data.yaml ‡∏ä‡∏µ‡πâ‡πÑ‡∏õ‡∏¢‡∏±‡∏á primary folder
- [ ] ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies: `pip install transformers timm huggingface_hub`
- [ ] ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ HuggingFace token (‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ DINOv3)

---

**‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏î‡∏¢:** Claude Code
**‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:** 2025-11-21
**‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô:** 1.0 (Greyscale Triple Input)
